{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "734249d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the whole file\n",
    "import pandas as pd \n",
    "df= pd.read_csv(\"train_set1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "778aaff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>docstring</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>func_name</th>\n",
       "      <th>language</th>\n",
       "      <th>original_string</th>\n",
       "      <th>partition</th>\n",
       "      <th>path</th>\n",
       "      <th>repo</th>\n",
       "      <th>sha</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>protected final void bindIndexed(Configuration...</td>\n",
       "      <td>['protected', 'final', 'void', 'bindIndexed', ...</td>\n",
       "      <td>Bind indexed elements to the supplied collecti...</td>\n",
       "      <td>['Bind', 'indexed', 'elements', 'to', 'the', '...</td>\n",
       "      <td>IndexedElementsBinder.bindIndexed</td>\n",
       "      <td>java</td>\n",
       "      <td>protected final void bindIndexed(Configuration...</td>\n",
       "      <td>train</td>\n",
       "      <td>spring-boot-project/spring-boot/src/main/java/...</td>\n",
       "      <td>spring-projects/spring-boot</td>\n",
       "      <td>0b27f7c70e164b2b1a96477f1d9c1acba56790c1</td>\n",
       "      <td>https://github.com/spring-projects/spring-boot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>public void setServletRegistrationBeans(\\n\\t\\t...</td>\n",
       "      <td>['public', 'void', 'setServletRegistrationBean...</td>\n",
       "      <td>Set {@link ServletRegistrationBean}s that the ...</td>\n",
       "      <td>['Set', '{']</td>\n",
       "      <td>AbstractFilterRegistrationBean.setServletRegis...</td>\n",
       "      <td>java</td>\n",
       "      <td>public void setServletRegistrationBeans(\\n\\t\\t...</td>\n",
       "      <td>train</td>\n",
       "      <td>spring-boot-project/spring-boot/src/main/java/...</td>\n",
       "      <td>spring-projects/spring-boot</td>\n",
       "      <td>0b27f7c70e164b2b1a96477f1d9c1acba56790c1</td>\n",
       "      <td>https://github.com/spring-projects/spring-boot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>public void addServletRegistrationBeans(\\n\\t\\t...</td>\n",
       "      <td>['public', 'void', 'addServletRegistrationBean...</td>\n",
       "      <td>Add {@link ServletRegistrationBean}s for the f...</td>\n",
       "      <td>['Add', '{']</td>\n",
       "      <td>AbstractFilterRegistrationBean.addServletRegis...</td>\n",
       "      <td>java</td>\n",
       "      <td>public void addServletRegistrationBeans(\\n\\t\\t...</td>\n",
       "      <td>train</td>\n",
       "      <td>spring-boot-project/spring-boot/src/main/java/...</td>\n",
       "      <td>spring-projects/spring-boot</td>\n",
       "      <td>0b27f7c70e164b2b1a96477f1d9c1acba56790c1</td>\n",
       "      <td>https://github.com/spring-projects/spring-boot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>public void setServletNames(Collection&lt;String&gt;...</td>\n",
       "      <td>['public', 'void', 'setServletNames', '(', 'Co...</td>\n",
       "      <td>Set servlet names that the filter will be regi...</td>\n",
       "      <td>['Set', 'servlet', 'names', 'that', 'the', 'fi...</td>\n",
       "      <td>AbstractFilterRegistrationBean.setServletNames</td>\n",
       "      <td>java</td>\n",
       "      <td>public void setServletNames(Collection&lt;String&gt;...</td>\n",
       "      <td>train</td>\n",
       "      <td>spring-boot-project/spring-boot/src/main/java/...</td>\n",
       "      <td>spring-projects/spring-boot</td>\n",
       "      <td>0b27f7c70e164b2b1a96477f1d9c1acba56790c1</td>\n",
       "      <td>https://github.com/spring-projects/spring-boot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>public void addServletNames(String... servletN...</td>\n",
       "      <td>['public', 'void', 'addServletNames', '(', 'St...</td>\n",
       "      <td>Add servlet names for the filter.\\n@param serv...</td>\n",
       "      <td>['Add', 'servlet', 'names', 'for', 'the', 'fil...</td>\n",
       "      <td>AbstractFilterRegistrationBean.addServletNames</td>\n",
       "      <td>java</td>\n",
       "      <td>public void addServletNames(String... servletN...</td>\n",
       "      <td>train</td>\n",
       "      <td>spring-boot-project/spring-boot/src/main/java/...</td>\n",
       "      <td>spring-projects/spring-boot</td>\n",
       "      <td>0b27f7c70e164b2b1a96477f1d9c1acba56790c1</td>\n",
       "      <td>https://github.com/spring-projects/spring-boot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454446</th>\n",
       "      <td>public static String primArrayToString(Object ...</td>\n",
       "      <td>['public', 'static', 'String', 'primArrayToStr...</td>\n",
       "      <td>Returns the primitive array {@link Object#toSt...</td>\n",
       "      <td>['Returns', 'the', 'primitive', 'array', '{', ...</td>\n",
       "      <td>Arrays2.primArrayToString</td>\n",
       "      <td>java</td>\n",
       "      <td>public static String primArrayToString(Object ...</td>\n",
       "      <td>train</td>\n",
       "      <td>benayn-ustyle/src/main/java/com/benayn/ustyle/...</td>\n",
       "      <td>jronrun/benayn</td>\n",
       "      <td>7585152e10e4cac07b4274c65f1c72ad7061ae69</td>\n",
       "      <td>https://github.com/jronrun/benayn/blob/7585152...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454447</th>\n",
       "      <td>public static &lt;T&gt; Object unwraps(T[] target) {...</td>\n",
       "      <td>['public', 'static', '&lt;', 'T', '&gt;', 'Object', ...</td>\n",
       "      <td>Converts the given object array to primitive a...</td>\n",
       "      <td>['Converts', 'the', 'given', 'object', 'array'...</td>\n",
       "      <td>Arrays2.unwraps</td>\n",
       "      <td>java</td>\n",
       "      <td>public static &lt;T&gt; Object unwraps(T[] target) {...</td>\n",
       "      <td>train</td>\n",
       "      <td>benayn-ustyle/src/main/java/com/benayn/ustyle/...</td>\n",
       "      <td>jronrun/benayn</td>\n",
       "      <td>7585152e10e4cac07b4274c65f1c72ad7061ae69</td>\n",
       "      <td>https://github.com/jronrun/benayn/blob/7585152...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454448</th>\n",
       "      <td>static Object add(Object array, int index, Obj...</td>\n",
       "      <td>['static', 'Object', 'add', '(', 'Object', 'ar...</td>\n",
       "      <td>Adds the element at the specified position fro...</td>\n",
       "      <td>['Adds', 'the', 'element', 'at', 'the', 'speci...</td>\n",
       "      <td>Arrays2.add</td>\n",
       "      <td>java</td>\n",
       "      <td>static Object add(Object array, int index, Obj...</td>\n",
       "      <td>train</td>\n",
       "      <td>benayn-ustyle/src/main/java/com/benayn/ustyle/...</td>\n",
       "      <td>jronrun/benayn</td>\n",
       "      <td>7585152e10e4cac07b4274c65f1c72ad7061ae69</td>\n",
       "      <td>https://github.com/jronrun/benayn/blob/7585152...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454449</th>\n",
       "      <td>public static Object remove(Object array, int ...</td>\n",
       "      <td>['public', 'static', 'Object', 'remove', '(', ...</td>\n",
       "      <td>Removes the element at the specified position ...</td>\n",
       "      <td>['Removes', 'the', 'element', 'at', 'the', 'sp...</td>\n",
       "      <td>Arrays2.remove</td>\n",
       "      <td>java</td>\n",
       "      <td>public static Object remove(Object array, int ...</td>\n",
       "      <td>train</td>\n",
       "      <td>benayn-ustyle/src/main/java/com/benayn/ustyle/...</td>\n",
       "      <td>jronrun/benayn</td>\n",
       "      <td>7585152e10e4cac07b4274c65f1c72ad7061ae69</td>\n",
       "      <td>https://github.com/jronrun/benayn/blob/7585152...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454450</th>\n",
       "      <td>@SuppressWarnings(\"unchecked\")\\n\\tpublic stati...</td>\n",
       "      <td>['@', 'SuppressWarnings', '(', '\"unchecked\"', ...</td>\n",
       "      <td>Converts the given target as an array of primi...</td>\n",
       "      <td>['Converts', 'the', 'given', 'target', 'as', '...</td>\n",
       "      <td>Arrays2.wraps</td>\n",
       "      <td>java</td>\n",
       "      <td>@SuppressWarnings(\"unchecked\")\\n\\tpublic stati...</td>\n",
       "      <td>train</td>\n",
       "      <td>benayn-ustyle/src/main/java/com/benayn/ustyle/...</td>\n",
       "      <td>jronrun/benayn</td>\n",
       "      <td>7585152e10e4cac07b4274c65f1c72ad7061ae69</td>\n",
       "      <td>https://github.com/jronrun/benayn/blob/7585152...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>454451 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     code  \\\n",
       "0       protected final void bindIndexed(Configuration...   \n",
       "1       public void setServletRegistrationBeans(\\n\\t\\t...   \n",
       "2       public void addServletRegistrationBeans(\\n\\t\\t...   \n",
       "3       public void setServletNames(Collection<String>...   \n",
       "4       public void addServletNames(String... servletN...   \n",
       "...                                                   ...   \n",
       "454446  public static String primArrayToString(Object ...   \n",
       "454447  public static <T> Object unwraps(T[] target) {...   \n",
       "454448  static Object add(Object array, int index, Obj...   \n",
       "454449  public static Object remove(Object array, int ...   \n",
       "454450  @SuppressWarnings(\"unchecked\")\\n\\tpublic stati...   \n",
       "\n",
       "                                              code_tokens  \\\n",
       "0       ['protected', 'final', 'void', 'bindIndexed', ...   \n",
       "1       ['public', 'void', 'setServletRegistrationBean...   \n",
       "2       ['public', 'void', 'addServletRegistrationBean...   \n",
       "3       ['public', 'void', 'setServletNames', '(', 'Co...   \n",
       "4       ['public', 'void', 'addServletNames', '(', 'St...   \n",
       "...                                                   ...   \n",
       "454446  ['public', 'static', 'String', 'primArrayToStr...   \n",
       "454447  ['public', 'static', '<', 'T', '>', 'Object', ...   \n",
       "454448  ['static', 'Object', 'add', '(', 'Object', 'ar...   \n",
       "454449  ['public', 'static', 'Object', 'remove', '(', ...   \n",
       "454450  ['@', 'SuppressWarnings', '(', '\"unchecked\"', ...   \n",
       "\n",
       "                                                docstring  \\\n",
       "0       Bind indexed elements to the supplied collecti...   \n",
       "1       Set {@link ServletRegistrationBean}s that the ...   \n",
       "2       Add {@link ServletRegistrationBean}s for the f...   \n",
       "3       Set servlet names that the filter will be regi...   \n",
       "4       Add servlet names for the filter.\\n@param serv...   \n",
       "...                                                   ...   \n",
       "454446  Returns the primitive array {@link Object#toSt...   \n",
       "454447  Converts the given object array to primitive a...   \n",
       "454448  Adds the element at the specified position fro...   \n",
       "454449  Removes the element at the specified position ...   \n",
       "454450  Converts the given target as an array of primi...   \n",
       "\n",
       "                                         docstring_tokens  \\\n",
       "0       ['Bind', 'indexed', 'elements', 'to', 'the', '...   \n",
       "1                                            ['Set', '{']   \n",
       "2                                            ['Add', '{']   \n",
       "3       ['Set', 'servlet', 'names', 'that', 'the', 'fi...   \n",
       "4       ['Add', 'servlet', 'names', 'for', 'the', 'fil...   \n",
       "...                                                   ...   \n",
       "454446  ['Returns', 'the', 'primitive', 'array', '{', ...   \n",
       "454447  ['Converts', 'the', 'given', 'object', 'array'...   \n",
       "454448  ['Adds', 'the', 'element', 'at', 'the', 'speci...   \n",
       "454449  ['Removes', 'the', 'element', 'at', 'the', 'sp...   \n",
       "454450  ['Converts', 'the', 'given', 'target', 'as', '...   \n",
       "\n",
       "                                                func_name language  \\\n",
       "0                       IndexedElementsBinder.bindIndexed     java   \n",
       "1       AbstractFilterRegistrationBean.setServletRegis...     java   \n",
       "2       AbstractFilterRegistrationBean.addServletRegis...     java   \n",
       "3          AbstractFilterRegistrationBean.setServletNames     java   \n",
       "4          AbstractFilterRegistrationBean.addServletNames     java   \n",
       "...                                                   ...      ...   \n",
       "454446                          Arrays2.primArrayToString     java   \n",
       "454447                                    Arrays2.unwraps     java   \n",
       "454448                                        Arrays2.add     java   \n",
       "454449                                     Arrays2.remove     java   \n",
       "454450                                      Arrays2.wraps     java   \n",
       "\n",
       "                                          original_string partition  \\\n",
       "0       protected final void bindIndexed(Configuration...     train   \n",
       "1       public void setServletRegistrationBeans(\\n\\t\\t...     train   \n",
       "2       public void addServletRegistrationBeans(\\n\\t\\t...     train   \n",
       "3       public void setServletNames(Collection<String>...     train   \n",
       "4       public void addServletNames(String... servletN...     train   \n",
       "...                                                   ...       ...   \n",
       "454446  public static String primArrayToString(Object ...     train   \n",
       "454447  public static <T> Object unwraps(T[] target) {...     train   \n",
       "454448  static Object add(Object array, int index, Obj...     train   \n",
       "454449  public static Object remove(Object array, int ...     train   \n",
       "454450  @SuppressWarnings(\"unchecked\")\\n\\tpublic stati...     train   \n",
       "\n",
       "                                                     path  \\\n",
       "0       spring-boot-project/spring-boot/src/main/java/...   \n",
       "1       spring-boot-project/spring-boot/src/main/java/...   \n",
       "2       spring-boot-project/spring-boot/src/main/java/...   \n",
       "3       spring-boot-project/spring-boot/src/main/java/...   \n",
       "4       spring-boot-project/spring-boot/src/main/java/...   \n",
       "...                                                   ...   \n",
       "454446  benayn-ustyle/src/main/java/com/benayn/ustyle/...   \n",
       "454447  benayn-ustyle/src/main/java/com/benayn/ustyle/...   \n",
       "454448  benayn-ustyle/src/main/java/com/benayn/ustyle/...   \n",
       "454449  benayn-ustyle/src/main/java/com/benayn/ustyle/...   \n",
       "454450  benayn-ustyle/src/main/java/com/benayn/ustyle/...   \n",
       "\n",
       "                               repo                                       sha  \\\n",
       "0       spring-projects/spring-boot  0b27f7c70e164b2b1a96477f1d9c1acba56790c1   \n",
       "1       spring-projects/spring-boot  0b27f7c70e164b2b1a96477f1d9c1acba56790c1   \n",
       "2       spring-projects/spring-boot  0b27f7c70e164b2b1a96477f1d9c1acba56790c1   \n",
       "3       spring-projects/spring-boot  0b27f7c70e164b2b1a96477f1d9c1acba56790c1   \n",
       "4       spring-projects/spring-boot  0b27f7c70e164b2b1a96477f1d9c1acba56790c1   \n",
       "...                             ...                                       ...   \n",
       "454446               jronrun/benayn  7585152e10e4cac07b4274c65f1c72ad7061ae69   \n",
       "454447               jronrun/benayn  7585152e10e4cac07b4274c65f1c72ad7061ae69   \n",
       "454448               jronrun/benayn  7585152e10e4cac07b4274c65f1c72ad7061ae69   \n",
       "454449               jronrun/benayn  7585152e10e4cac07b4274c65f1c72ad7061ae69   \n",
       "454450               jronrun/benayn  7585152e10e4cac07b4274c65f1c72ad7061ae69   \n",
       "\n",
       "                                                      url  \n",
       "0       https://github.com/spring-projects/spring-boot...  \n",
       "1       https://github.com/spring-projects/spring-boot...  \n",
       "2       https://github.com/spring-projects/spring-boot...  \n",
       "3       https://github.com/spring-projects/spring-boot...  \n",
       "4       https://github.com/spring-projects/spring-boot...  \n",
       "...                                                   ...  \n",
       "454446  https://github.com/jronrun/benayn/blob/7585152...  \n",
       "454447  https://github.com/jronrun/benayn/blob/7585152...  \n",
       "454448  https://github.com/jronrun/benayn/blob/7585152...  \n",
       "454449  https://github.com/jronrun/benayn/blob/7585152...  \n",
       "454450  https://github.com/jronrun/benayn/blob/7585152...  \n",
       "\n",
       "[454451 rows x 12 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c9448495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import string\n",
    "import re\n",
    "import pandas as pd \n",
    "import javalang\n",
    "from javalang.ast import Node\n",
    "import os\n",
    "from anytree import AnyNode, RenderTree\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import transformers\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a05dd293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating abstract syntax tree\n",
    "error=[]\n",
    "dfset = df.drop([71],axis = 0)\n",
    "for i, row in dfset.iterrows():\n",
    "    try:\n",
    "        programtext = row[\"code\"]\n",
    "        programtokens=javalang.tokenizer.tokenize(programtext)\n",
    "        #print(\"programtokens\",list(programtokens))\n",
    "        parser=javalang.parse.Parser(programtokens)\n",
    "        programast=parser.parse_member_declaration()\n",
    "    except:\n",
    "        error.append(i)\n",
    "        continue\n",
    "df_set = dfset.drop(error,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "20abd7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398\n"
     ]
    }
   ],
   "source": [
    "print(len(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8f06e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(['code','docstring','func_name','language','original_string','partition','path','repo','sha','url'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ae703c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removal of data with incomplete comments\n",
    "for i, row in df1.iterrows():\n",
    "    str1 = row['docstring_tokens']\n",
    "    if '{' in str1:\n",
    "        df1 = df1.drop([i],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5200851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removal of data with blank comments\n",
    "for i, row in df1.iterrows():\n",
    "    if row['docstring_tokens'] == '[]':\n",
    "        df1 = df1.drop([i],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "22e7a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove punctuation and split words\n",
    "punctuation_string = string.punctuation\n",
    "code_tokens=[]\n",
    "doc_tokens=[]\n",
    "for i, row in df1.iterrows():\n",
    "    word = row['code_tokens']\n",
    "    word1 = row['docstring_tokens']\n",
    "    for j in punctuation_string:\n",
    "        word = word.replace(j, '')\n",
    "        word1 = word1.replace(j, '')\n",
    "    word_list = word.split()\n",
    "    doc_list = word1.split()\n",
    "    list_alpha = []\n",
    "    list_doc = []\n",
    "    for word in word_list:\n",
    "        word_split = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1', word)).split()\n",
    "        list_alpha.append(word_split)\n",
    "    for word in doc_list:\n",
    "        list_doc.append(word)\n",
    "    list_alpha = [m for item in list_alpha for m in item]\n",
    "    list_alpha = [item.lower() for item in list_alpha]\n",
    "    list_doc = [item.lower() for item in list_doc]\n",
    "    row['code_tokens'] = list_alpha\n",
    "    row['docstring_tokens'] = list_doc\n",
    "    code_tokens.append(list_alpha)\n",
    "    doc_tokens.append(list_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e6869400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert string to list\n",
    "punctuation_string = string.punctuation\n",
    "for i, row in df1.iterrows():\n",
    "    word1 = row['code_tokens']\n",
    "    word2 = row['docstring_tokens']\n",
    "    for j in punctuation_string:\n",
    "        word1 = word1.replace(j, '')\n",
    "        word2 = word2.replace(j, '')\n",
    "    word_list1 = word1.split()\n",
    "    word_list2 = word2.split()\n",
    "    row['code_tokens'] = word_list1\n",
    "    row['docstring_tokens'] = word_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c566d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting data contains Chinese\n",
    "def is_contain_chinese(check_str):\n",
    "    for ch in check_str:\n",
    "        if u'\\u4e00' <= ch <= u'\\u9fff':\n",
    "            return True\n",
    "    return False\n",
    "for i, row in df1.iterrows():\n",
    "    str1 = \"\".join(row['docstring_tokens'])\n",
    "    if is_contain_chinese(str1):\n",
    "        df1 = df1.drop([i],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8f06037",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(['Unnamed: 0'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d6787c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>docstring_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[protected, final, void, bind, indexed, config...</td>\n",
       "      <td>[bind, indexed, elements, to, the, supplied, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[public, void, set, servlet, names, collection...</td>\n",
       "      <td>[set, servlet, names, that, the, filter, will,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[public, void, add, servlet, names, string, se...</td>\n",
       "      <td>[add, servlet, names, for, the, filter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[public, void, set, url, patterns, collection,...</td>\n",
       "      <td>[set, the, url, patterns, that, the, filter, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[public, void, add, url, patterns, string, url...</td>\n",
       "      <td>[add, url, patterns, as, defined, in, the, ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454446</th>\n",
       "      <td>[public, static, string, prim, array, to, stri...</td>\n",
       "      <td>[returns, the, primitive, array, link, objectt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454447</th>\n",
       "      <td>[public, static, t, object, unwraps, t, target...</td>\n",
       "      <td>[converts, the, given, object, array, to, prim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454448</th>\n",
       "      <td>[static, object, add, object, array, int, inde...</td>\n",
       "      <td>[adds, the, element, at, the, specified, posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454449</th>\n",
       "      <td>[public, static, object, remove, object, array...</td>\n",
       "      <td>[removes, the, element, at, the, specified, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454450</th>\n",
       "      <td>[suppress, warnings, unchecked, public, static...</td>\n",
       "      <td>[converts, the, given, target, as, an, array, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425121 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              code_tokens  \\\n",
       "0       [protected, final, void, bind, indexed, config...   \n",
       "3       [public, void, set, servlet, names, collection...   \n",
       "4       [public, void, add, servlet, names, string, se...   \n",
       "5       [public, void, set, url, patterns, collection,...   \n",
       "6       [public, void, add, url, patterns, string, url...   \n",
       "...                                                   ...   \n",
       "454446  [public, static, string, prim, array, to, stri...   \n",
       "454447  [public, static, t, object, unwraps, t, target...   \n",
       "454448  [static, object, add, object, array, int, inde...   \n",
       "454449  [public, static, object, remove, object, array...   \n",
       "454450  [suppress, warnings, unchecked, public, static...   \n",
       "\n",
       "                                         docstring_tokens  \n",
       "0       [bind, indexed, elements, to, the, supplied, c...  \n",
       "3       [set, servlet, names, that, the, filter, will,...  \n",
       "4                 [add, servlet, names, for, the, filter]  \n",
       "5       [set, the, url, patterns, that, the, filter, w...  \n",
       "6       [add, url, patterns, as, defined, in, the, ser...  \n",
       "...                                                   ...  \n",
       "454446  [returns, the, primitive, array, link, objectt...  \n",
       "454447  [converts, the, given, object, array, to, prim...  \n",
       "454448  [adds, the, element, at, the, specified, posit...  \n",
       "454449  [removes, the, element, at, the, specified, po...  \n",
       "454450  [converts, the, given, target, as, an, array, ...  \n",
       "\n",
       "[425121 rows x 2 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0d880950",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index = list(df1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "57cdd3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a class to split the dataset\n",
    "def split_ids(id_list, train=.7, valid=0.1, test=0.2):\n",
    "    \n",
    "    list_copy = id_list.copy()\n",
    "    random.shuffle(list_copy)\n",
    "    \n",
    "    train_size = math.floor(len(list_copy) * train)\n",
    "    valid_size = math.floor(len(list_copy) * valid)\n",
    "    \n",
    "    return list_copy[:train_size], list_copy[train_size:(train_size + valid_size)], list_copy[(train_size + valid_size):]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "721d8ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set = split_ids(list_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0b385f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297584 42512 85025\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set),len(valid_set),len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c1e230cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df1.loc[train_set]\n",
    "df_valid = df1.loc[valid_set]\n",
    "df_test = df1.loc[test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "79f3955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('df_train2.csv')\n",
    "df_valid.to_csv('df_valid2.csv')\n",
    "df_test.to_csv('df_test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6d7b1c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('df_train2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c8acdf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the model on 1000 pieces of data\n",
    "df_train = df_train.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "87de9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#str to list\n",
    "punctuation_string = string.punctuation\n",
    "for i, row in df_train.iterrows():\n",
    "    word1 = row['code_tokens']\n",
    "    word2 = row['docstring_tokens']\n",
    "    for j in punctuation_string:\n",
    "        word1 = word1.replace(j, '')\n",
    "        word2 = word2.replace(j, '')\n",
    "    word_list1 = word1.split()\n",
    "    word_list2 = word2.split()\n",
    "    row['code_tokens'] = word_list1\n",
    "    row['docstring_tokens'] = word_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b5fbec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lengthCheck(df):\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    for i, row in df.iterrows():\n",
    "        length1 = len(df.iloc[i].iat[0])\n",
    "        length2 = len(df.iloc[i].iat[1])\n",
    "        list1.append(length1)\n",
    "        list2.append(length2)\n",
    "    return list1,list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a7703fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_list1,length_list2 = lengthCheck(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "231ba713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910\n",
      "1000\n",
      "998\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "#determine 200 is the fixed length\n",
    "num = sum(i <200 for i in length_list1)\n",
    "print(num)\n",
    "print(len(length_list1))\n",
    "num = sum(i <200 for i in length_list2)\n",
    "print(num)\n",
    "print(len(length_list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "99278c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutLength(df):\n",
    "    for i, row in df.iterrows():\n",
    "        length1 = len(df.iloc[i].iat[0])\n",
    "        length2 = len(df.iloc[i].iat[1])\n",
    "        a = df.iloc[i].iat[0]\n",
    "        b = df.iloc[i].iat[1]\n",
    "        if length1>200:\n",
    "            del a[200:]\n",
    "        if length2>200:\n",
    "             del b[200:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "da6f5799",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cut = cutLength(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1704a8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the tokens have appeared less than 3 times\n",
    "list_x = []\n",
    "list_Y = []\n",
    "for i, row in df_train_cut.iterrows():\n",
    "    list_x.append(row['code_tokens'])\n",
    "    list_Y.append(row['docstring_tokens'])\n",
    "list_a = [m for item in list_x for m in item]\n",
    "list_b = [m for item in list_Y for m in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "441cd1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2059\n",
      "610\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "count = Counter(list_a)\n",
    "word_a = [x[0] for x in count.items() if x[1] > 3]\n",
    "print(len(word_a))\n",
    "count1 = Counter(list_b)\n",
    "word_b = [x[0] for x in count1.items() if x[1] > 3]\n",
    "print(len(word_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a06c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build dictionary\n",
    "size1 = len(word_a)\n",
    "size2 = len(word_b)\n",
    "tokenids = range(3,size1+3)\n",
    "docids = range(3,size2+3)\n",
    "src_dict = dict(zip(word_a, tokenids))\n",
    "trg_dict = dict(zip(word_b, docids))\n",
    "src_dict['<sos>']=0\n",
    "src_dict['<eos>']=1\n",
    "src_dict['<unk>']=2\n",
    "trg_dict['<sos>']=0\n",
    "trg_dict['<eos>']=1\n",
    "trg_dict['<unk>']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95785f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping data through the dictionary\n",
    "for i in list_trg:\n",
    "    list_vocab_a=[]\n",
    "    list_vocab_a.append(trg_dict['<sos>'])\n",
    "    for m in i:\n",
    "        if not m in trg_dict.keys():\n",
    "            list_vocab_a.append(trg_dict['<unk>'])\n",
    "        else:\n",
    "            list_vocab_a.append(trg_dict[m])\n",
    "    list_vocab_a.append(trg_dict['<eos>'])\n",
    "    dic_trg.append(list_vocab_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54431ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 23\n"
     ]
    }
   ],
   "source": [
    "print(len(src_dict),len(trg_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0987d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_dict['ignore_idx']=len(trg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c7e2435",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Subset(Dataset):\n",
    "\n",
    "    def __init__(self,s1,s2,ignore):\n",
    "        self.s1 = s1\n",
    "        self.s2 = s2\n",
    "        self.src = s1\n",
    "        self.trg = s2\n",
    "        self.ig = ignore\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        while len(self.src[index])< 202:\n",
    "            self.src[index].append(1)\n",
    "        \n",
    "        while len(self.trg[index])< 202:\n",
    "            self.trg[index].append(self.ig)\n",
    "        return torch.LongTensor(self.src[index]), torch.LongTensor(self.trg[index])\n",
    "    def __len__(self):\n",
    "        return len(self.s1)\n",
    "    \n",
    "dataset_train = Data_Subset(dic_src, dic_trg,trg_dict['ignore_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4fec0e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=5,  \n",
    "        shuffle=True,\n",
    "        num_workers=0, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83af9175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 202])\n",
      "torch.Size([5, 202])\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_loader)\n",
    "a,b = train_iter.next()\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "61c30960",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "       \n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        \n",
    "        #input = [batch size]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "                \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        \n",
    "        #output = [seq len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "        \n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2bca7e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04ac0a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "    \n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "19f194fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(src_dict)\n",
    "OUTPUT_DIM = len(trg_dict)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "device = torch.device('cpu')\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c46c68dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(57, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(24, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=24, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "52180200",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "064053cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index = len(trg_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "72debd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, (src,trg) in enumerate(iterator):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "be19fa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.024348735809326\n",
      "1.8447325825691223\n",
      "0.7550484240055084\n",
      "1.396475613117218\n",
      "0.7638779729604721\n",
      "0.8837899267673492\n",
      "0.7894061207771301\n",
      "0.6787824630737305\n",
      "0.7395245730876923\n",
      "0.8383639752864838\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
    "    \n",
    "    print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04162602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baaf17b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc879be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
